{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surface-worker",
   "metadata": {},
   "source": [
    "# TD n°3 : Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affected-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-procurement",
   "metadata": {},
   "source": [
    "## 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coupled-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "np_array = np.array([10, 20, 30, 40, 50])\n",
    "pd_series = pd.Series(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-design",
   "metadata": {},
   "source": [
    "## 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7, 11], 'col2': [4, 5, 6, 9, 5, 0], 'col3': [7, 5, 8, 12, 1,11]})\n",
    "serie = df['col1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-orchestra",
   "metadata": {},
   "source": [
    "## 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chemical-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series(np.random.randint(1, 10, 9))\n",
    "positions = serie[serie % 5 == 0].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-harmony",
   "metadata": {},
   "source": [
    "## 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "front-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series([1,2,3,4,5,6,7,8,9,5,3])\n",
    "mean = serie.mean()\n",
    "std_dev = serie.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-election",
   "metadata": {},
   "source": [
    "## 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "round-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les deux séries sont-elles égales ? True\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data1 = [1, 8, 7, 5, 6, 5, 3, 4, 7, 1]\n",
    "data2 = [1, 8, 7, 5, 6, 5, 3, 4, 7, 1]\n",
    "\n",
    "# Création de deux séries Pandas\n",
    "serie1 = pd.Series(data1)\n",
    "serie2 = pd.Series(data2)\n",
    "\n",
    "# Vérification de l'égalité des deux séries\n",
    "egalite = serie1.equals(serie2)\n",
    "\n",
    "print(\"Les deux séries sont-elles égales ?\", egalite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-jerusalem",
   "metadata": {},
   "source": [
    "## 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "serie1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "serie2 = pd.Series([11, 8, 7, 5, 6, 5, 3, 4, 7, 1])\n",
    "dist = distance.euclidean(serie1, serie2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-instrument",
   "metadata": {},
   "source": [
    "## 7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(['Red', 'Green', 'Orange', 'Pink', 'Yellow', 'White'])\n",
    "filtered_words = words[words.str.count('[aeiou]') >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-roots",
   "metadata": {},
   "source": [
    "## 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forbidden-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "                    'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
    "                    'marks': [200, 210, 190, 222, 199]})\n",
    "df2 = pd.DataFrame({'student_id': ['S4', 'S5', 'S6'],\n",
    "                    'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse'],\n",
    "                    'marks': [201, 200, 198]})\n",
    "combined_df = pd.concat([df1, df2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-charter",
   "metadata": {},
   "source": [
    "## 9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controversial-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({'student_id': ['S6'], 'name': ['Scarlette Fisher'], 'marks': [205]})\n",
    "df1 = df1.add(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-assist",
   "metadata": {},
   "source": [
    "## 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "driven-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.merge(df1, df2, on='student_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-leonard",
   "metadata": {},
   "source": [
    "## 11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distant-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K1'],\n",
    "                    'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                    'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                    'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
    "df2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                    'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                    'S': ['S0', 'S1', 'S2', 'S3']})\n",
    "merged_df = pd.merge(df1, df2, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-layer",
   "metadata": {},
   "source": [
    "## 12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worst-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'school': ['S1', 'S2', 'S3', 'S1', 'S2'],\n",
    "    'class': ['s001', 's002', 's003', 's001', 's002'],\n",
    "    'name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill'],\n",
    "    'date_of_birth': ['15/05/2002', '17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002'],\n",
    "    'age': [12, 12, 13, 13, 12],\n",
    "    'height': [173, 192, 186, 167, 151],\n",
    "    'weight': [35, 32, 33, 30, 31],\n",
    "    'address': ['street1', 'street2', 'street3', 'street4', 'street5']\n",
    "})\n",
    "stats = df.groupby('school')['age'].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-burke",
   "metadata": {},
   "source": [
    "## 13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "known-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ord_no': [70001, 70002, 70003, 70004, 70005, 70006, 70007, 70008, 70009, 70010, 70011, 70012],\n",
    "    'purch_amt': [150.50, 65.26, 2480.40, 110.50, 948.50, 2400.60, 5760.00, 1983.43, 250.45, 75.29, 3045.60, 150.50],\n",
    "    'ord_date': ['2012-10-05', '2012-10-05', '2012-10-10', '2012-10-10', '2012-09-10', '2012-09-10', '2012-07-27', '2012-07-27', '2012-08-17', '2012-08-17', '2012-04-25', '2012-04-25'],\n",
    "    'customer_id': [3005, 3001, 3009, 3003, 3002, 3004, 3003, 3002, 3008, 3003, 3002, 3001],\n",
    "    'salesman_id': [5002, 5003, 5004, 5006, 5007, 5003, 5001, 5001, 5005, 5002, 5001, 5004]\n",
    "})\n",
    "grouped = df.groupby('customer_id')['purch_amt'].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-mobile",
   "metadata": {},
   "source": [
    "## 14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unique-tours",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'alphabet_stock_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c3f3824588d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Remplacez 'file_path' par le chemin d'accès réel au fichier CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alphabet_stock_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1879\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alphabet_stock_data.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remplacez 'file_path' par le chemin d'accès réel au fichier CSV\n",
    "file_path = 'alphabet_stock_data.csv'\n",
    "stock_data = pd.read_csv(file_path)\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# Filtrer les données entre deux dates\n",
    "start_date = '2020-04-01'\n",
    "end_date = '2020-09-30'\n",
    "mask = (stock_data['Date'] >= start_date) & (stock_data['Date'] <= end_date)\n",
    "filtered_data = stock_data.loc[mask]\n",
    "\n",
    "# Créer un graphique en ligne\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(filtered_data['Date'], filtered_data['Close'])\n",
    "plt.title('Alphabet Inc. Historical Stock Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-cardiff",
   "metadata": {},
   "source": [
    "## 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que la colonne 'Close' contient les prix de clôture des actions\n",
    "stock_data['Daily_Return'] = stock_data['Close'].pct_change()\n",
    "\n",
    "# Filtrer les données pour les retours quotidiens entre deux dates\n",
    "mask = (stock_data['Date'] >= start_date) & (stock_data['Date'] <= end_date)\n",
    "filtered_data = stock_data.loc[mask]\n",
    "\n",
    "# Créer un histogramme pour les retours quotidiens\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(filtered_data['Daily_Return'].dropna(), bins=50)\n",
    "plt.title('Alphabet Inc. Daily Return Distribution')\n",
    "plt.xlabel('Daily Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
